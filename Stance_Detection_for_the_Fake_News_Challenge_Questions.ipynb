{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Stance_Detection_for_the_Fake_News_Challenge_Questions.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "QI9jhXKPCFcJ"
      },
      "source": [
        "# Stance Detection for the Fake News Challenge\n",
        "\n",
        "## Identifying Textual Relationships with Deep Neural Nets\n",
        "\n",
        "### Check the problem context [here](https://drive.google.com/open?id=1KfWaZyQdGBw8AUTacJ2yY86Yxgw2Xwq0).\n",
        "\n",
        "### Download files required for the project from [here](https://drive.google.com/open?id=10yf39ifEwVihw4xeJJR60oeFBY30Y5J8)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "vSNgdEMpenpE"
      },
      "source": [
        "## Step1: Load the given dataset  \n",
        "\n",
        "1. Mount the google drive\n",
        "\n",
        "2. Import Glove embeddings\n",
        "\n",
        "3. Import the test and train datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "aPOZRohMiSpQ"
      },
      "source": [
        "### Mount the google drive to access required project files\n",
        "\n",
        "Run the below commands"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7AS39z1XgFpT",
        "colab": {}
      },
      "source": [
        "from google.colab import drive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "S_7yCFdzgFsH",
        "outputId": "bc373296-d8ae-4c58-f674-78621bd4170f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        }
      },
      "source": [
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "bhZdJ4zpwWzN"
      },
      "source": [
        "#### Path for Project files on google drive\n",
        "\n",
        "**Note:** You need to change this path according where you have kept the files in google drive. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Aol97RUogFuS",
        "colab": {}
      },
      "source": [
        "project_path = \"/content/drive/My Drive/Colab Notebooks/Sequential NLP/Fake News Challenge/\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2ly0VxAnwJ2f"
      },
      "source": [
        "### Loading the Glove Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xmsPn6PF-cgL",
        "outputId": "83e63f4a-335d-4d82-b889-c8bf8fd135c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        }
      },
      "source": [
        "from zipfile import ZipFile\n",
        "with ZipFile(project_path+'glove.6B.zip', 'r') as z:\n",
        "  z.extractall()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-ec604e34a6f1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mzipfile\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mZipFile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproject_path\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'glove.6B.zip'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0mz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextractall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/lib/python3.6/zipfile.py\u001b[0m in \u001b[0;36mextractall\u001b[0;34m(self, path, members, pwd)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1523\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mzipinfo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmembers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1524\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extract_member\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzipinfo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpwd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1525\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/zipfile.py\u001b[0m in \u001b[0;36m_extract_member\u001b[0;34m(self, member, targetpath, pwd)\u001b[0m\n\u001b[1;32m   1576\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1577\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmember\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpwd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpwd\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1578\u001b[0;31m              \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtargetpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1579\u001b[0m             \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopyfileobj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: [Errno 30] Read-only file system: '/content/drive/My Drive/Colab Notebooks/Sequential NLP/Fake News Challenge/glove.6B.50d.txt'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "TjLJEQ_PwcGi"
      },
      "source": [
        "# Load the dataset [5 Marks]\n",
        "\n",
        "1. Using [read_csv()](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html) in pandas load the given train datasets files **`train_bodies.csv`** and **`train_stances.csv`**\n",
        "\n",
        "2. Using [merge](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.merge.html) command in pandas merge the two datasets based on the Body ID. \n",
        "\n",
        "Note: Save the final merged dataset in a dataframe with name **`dataset`**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "anYloEkd6LoK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6I4av_oH7HfY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.chdir('/content/drive/My Drive/Colab Notebooks/Sequential NLP/Fake News Challenge/')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7gXO1WZ-gFwm",
        "colab": {}
      },
      "source": [
        "df1=pd.read_csv('train_bodies.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z4c6uXQ_KOuh",
        "colab_type": "code",
        "outputId": "2561d3e1-0998-4945-f5a3-0bcd750e2c63",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        }
      },
      "source": [
        "df1.head()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Body ID</th>\n",
              "      <th>articleBody</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>A small meteorite crashed into a wooded area i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>Last week we hinted at what was to come as Ebo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>(NEWSER) – Wonder how long a Quarter Pounder w...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6</td>\n",
              "      <td>Posting photos of a gun-toting child online, I...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7</td>\n",
              "      <td>At least 25 suspected Boko Haram insurgents we...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Body ID                                        articleBody\n",
              "0        0  A small meteorite crashed into a wooded area i...\n",
              "1        4  Last week we hinted at what was to come as Ebo...\n",
              "2        5  (NEWSER) – Wonder how long a Quarter Pounder w...\n",
              "3        6  Posting photos of a gun-toting child online, I...\n",
              "4        7  At least 25 suspected Boko Haram insurgents we..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X07QADLrhThD",
        "colab_type": "code",
        "outputId": "0de9211e-2ffc-410c-d6c9-245086f0032c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "df1.articleBody[0]"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'A small meteorite crashed into a wooded area in Nicaragua\\'s capital of Managua overnight, the government said Sunday. Residents reported hearing a mysterious boom that left a 16-foot deep crater near the city\\'s airport, the Associated Press reports. \\n\\nGovernment spokeswoman Rosario Murillo said a committee formed by the government to study the event determined it was a \"relatively small\" meteorite that \"appears to have come off an asteroid that was passing close to Earth.\" House-sized asteroid 2014 RC, which measured 60 feet in diameter, skimmed the Earth this weekend, ABC News reports. \\nMurillo said Nicaragua will ask international experts to help local scientists in understanding what happened.\\n\\nThe crater left by the meteorite had a radius of 39 feet and a depth of 16 feet,  said Humberto Saballos, a volcanologist with the Nicaraguan Institute of Territorial Studies who was on the committee. He said it is still not clear if the meteorite disintegrated or was buried.\\n\\nHumberto Garcia, of the Astronomy Center at the National Autonomous University of Nicaragua, said the meteorite could be related to an asteroid that was forecast to pass by the planet Saturday night.\\n\\n\"We have to study it more because it could be ice or rock,\" he said.\\n\\nWilfried Strauch, an adviser to the Institute of Territorial Studies, said it was \"very strange that no one reported a streak of light. We have to ask if anyone has a photo or something.\"\\n\\nLocal residents reported hearing a loud boom Saturday night, but said they didn\\'t see anything strange in the sky.\\n\\n\"I was sitting on my porch and I saw nothing, then all of a sudden I heard a large blast. We thought it was a bomb because we felt an expansive wave,\" Jorge Santamaria told The Associated Press.\\n\\nThe site of the crater is near Managua\\'s international airport and an air force base. Only journalists from state media were allowed to visit it.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zBzp2CkECCp9",
        "colab_type": "code",
        "outputId": "0a79b9e1-3a43-42f2-edc8-12ab5ede7b33",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        }
      },
      "source": [
        "df1.count"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method DataFrame.count of       Body ID                                        articleBody\n",
              "0           0  A small meteorite crashed into a wooded area i...\n",
              "1           4  Last week we hinted at what was to come as Ebo...\n",
              "2           5  (NEWSER) – Wonder how long a Quarter Pounder w...\n",
              "3           6  Posting photos of a gun-toting child online, I...\n",
              "4           7  At least 25 suspected Boko Haram insurgents we...\n",
              "...       ...                                                ...\n",
              "1678     2528  Intelligence agencies hunting for identity of ...\n",
              "1679     2529  While Daleks \"know no fear\" and \"must not fear...\n",
              "1680     2530  More than 200 schoolgirls were kidnapped in Ap...\n",
              "1681     2531  A Guantanamo Bay prisoner released last year a...\n",
              "1682     2532  ANN ARBOR, Mich. – A pizza delivery man in Mic...\n",
              "\n",
              "[1683 rows x 2 columns]>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kosAWskdOOT8",
        "colab": {}
      },
      "source": [
        "df2=pd.read_csv('train_stances.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4pzDozoN6Vgc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df=df1.merge(df2, how='outer',on='Body ID')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "g4ycQbBCg20S"
      },
      "source": [
        "\n",
        "<h2> Check1:</h2>\n",
        "  \n",
        "<h3> You should see the below output if you run `dataset.head()` command as given below </h3>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "IUtF7iOmj11k",
        "outputId": "ad4971b5-a6a5-41a6-b9b1-d5a3ccacfe60",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        }
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Body ID</th>\n",
              "      <th>articleBody</th>\n",
              "      <th>Headline</th>\n",
              "      <th>Stance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>A small meteorite crashed into a wooded area i...</td>\n",
              "      <td>Soldier shot, Parliament locked down after gun...</td>\n",
              "      <td>unrelated</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>A small meteorite crashed into a wooded area i...</td>\n",
              "      <td>Tourist dubbed ‘Spider Man’ after spider burro...</td>\n",
              "      <td>unrelated</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>A small meteorite crashed into a wooded area i...</td>\n",
              "      <td>Luke Somers 'killed in failed rescue attempt i...</td>\n",
              "      <td>unrelated</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>A small meteorite crashed into a wooded area i...</td>\n",
              "      <td>BREAKING: Soldier shot at War Memorial in Ottawa</td>\n",
              "      <td>unrelated</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>A small meteorite crashed into a wooded area i...</td>\n",
              "      <td>Giant 8ft 9in catfish weighing 19 stone caught...</td>\n",
              "      <td>unrelated</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Body ID  ...     Stance\n",
              "0        0  ...  unrelated\n",
              "1        0  ...  unrelated\n",
              "2        0  ...  unrelated\n",
              "3        0  ...  unrelated\n",
              "4        0  ...  unrelated\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CnFq26qwhqhk",
        "colab_type": "code",
        "outputId": "bca08c9d-f932-4f97-e282-f099512b54a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        }
      },
      "source": [
        "df['articleBody']"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        A small meteorite crashed into a wooded area i...\n",
              "1        A small meteorite crashed into a wooded area i...\n",
              "2        A small meteorite crashed into a wooded area i...\n",
              "3        A small meteorite crashed into a wooded area i...\n",
              "4        A small meteorite crashed into a wooded area i...\n",
              "                               ...                        \n",
              "49967    ANN ARBOR, Mich. – A pizza delivery man in Mic...\n",
              "49968    ANN ARBOR, Mich. – A pizza delivery man in Mic...\n",
              "49969    ANN ARBOR, Mich. – A pizza delivery man in Mic...\n",
              "49970    ANN ARBOR, Mich. – A pizza delivery man in Mic...\n",
              "49971    ANN ARBOR, Mich. – A pizza delivery man in Mic...\n",
              "Name: articleBody, Length: 49972, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "tjzVz2ifijmj"
      },
      "source": [
        "## Step2: Data Pre-processing and setting some hyper parameters needed for model\n",
        "\n",
        "\n",
        "#### Run the code given below to set the required parameters.\n",
        "\n",
        "1. `MAX_SENTS` = Maximum no.of sentences to consider in an article.\n",
        "\n",
        "2. `MAX_SENT_LENGTH` = Maximum no.of words to consider in a sentence.\n",
        "\n",
        "3. `MAX_NB_WORDS` = Maximum no.of words in the total vocabualry.\n",
        "\n",
        "4. `MAX_SENTS_HEADING` = Maximum no.of sentences to consider in a heading of an article."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "KDXSdpvqjuqw",
        "colab": {}
      },
      "source": [
        "MAX_NB_WORDS = 20000\n",
        "MAX_SENTS = 20\n",
        "MAX_SENTS_HEADING = 1\n",
        "MAX_SENT_LENGTH = 20\n",
        "VALIDATION_SPLIT = 0.2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zwE7CPHdiDT-"
      },
      "source": [
        "### Download the `Punkt` from nltk using the commands given below. This is for sentence tokenization.\n",
        "\n",
        "For more info on how to use it, read [this](https://stackoverflow.com/questions/35275001/use-of-punktsentencetokenizer-in-nltk).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lsiKmyJUZ-hU",
        "outputId": "61dd5409-15f6-4de7-d0e4-78922382f64f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Gqwm_GbwwnhX"
      },
      "source": [
        "# Tokenizing the text and loading the pre-trained Glove word embeddings for each token  [5 marks] "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "WfZLR24mm32k"
      },
      "source": [
        "Keras provides [Tokenizer API](https://keras.io/preprocessing/text/) for preparing text. Read it before going any further."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "fLSn9S-5oG4Z"
      },
      "source": [
        "#### Import the Tokenizer from keras preprocessing text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "S-VUgh2yoMlR",
        "outputId": "83356319-517b-4a21-a11b-f62ea1f45fb6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        }
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0JNp34aVF058",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "eml0Lge4oOuh"
      },
      "source": [
        "#### Initialize the Tokenizer class with maximum vocabulary count as `MAX_NB_WORDS` initialized at the start of step2. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Qm85qirPofc2",
        "colab": {}
      },
      "source": [
        "tokenizer=keras.preprocessing.text.Tokenizer(num_words=MAX_NB_WORDS)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "HBe1KuXDosJ7"
      },
      "source": [
        "#### Now, using fit_on_texts() from Tokenizer class, lets encode the data \n",
        "\n",
        "Note: We need to fit articleBody and Headline also to cover all the words."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Q5rk-UyBlmyA",
        "colab": {}
      },
      "source": [
        "articles=tokenizer.fit_on_texts(df['articleBody'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QG3wqCtykI0r",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2cc6437d-f3d7-420e-834c-4bc0c5b3f3ae"
      },
      "source": [
        "tokenizer.word_index"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'the': 1,\n",
              " 'to': 2,\n",
              " 'a': 3,\n",
              " 'of': 4,\n",
              " 'in': 5,\n",
              " 'and': 6,\n",
              " 'that': 7,\n",
              " 'is': 8,\n",
              " 'was': 9,\n",
              " 'on': 10,\n",
              " 'for': 11,\n",
              " 'said': 12,\n",
              " 'he': 13,\n",
              " 'with': 14,\n",
              " 'it': 15,\n",
              " 'his': 16,\n",
              " 'have': 17,\n",
              " 'as': 18,\n",
              " 'by': 19,\n",
              " 'has': 20,\n",
              " 'from': 21,\n",
              " 'at': 22,\n",
              " 'be': 23,\n",
              " 'an': 24,\n",
              " 'not': 25,\n",
              " 'are': 26,\n",
              " 'been': 27,\n",
              " '”': 28,\n",
              " 'but': 29,\n",
              " 'this': 30,\n",
              " 'had': 31,\n",
              " 'who': 32,\n",
              " 'they': 33,\n",
              " 'after': 34,\n",
              " 'i': 35,\n",
              " 'were': 36,\n",
              " 'we': 37,\n",
              " 'will': 38,\n",
              " 'about': 39,\n",
              " 'one': 40,\n",
              " 'or': 41,\n",
              " 'which': 42,\n",
              " 'she': 43,\n",
              " 'video': 44,\n",
              " 'apple': 45,\n",
              " 'up': 46,\n",
              " 'would': 47,\n",
              " 'her': 48,\n",
              " 'state': 49,\n",
              " 'their': 50,\n",
              " 'also': 51,\n",
              " 'more': 52,\n",
              " 'when': 53,\n",
              " 'told': 54,\n",
              " 'out': 55,\n",
              " 'isis': 56,\n",
              " 'all': 57,\n",
              " 'no': 58,\n",
              " 'new': 59,\n",
              " 'people': 60,\n",
              " 'there': 61,\n",
              " 'you': 62,\n",
              " 'its': 63,\n",
              " 'if': 64,\n",
              " 'him': 65,\n",
              " 'news': 66,\n",
              " 'what': 67,\n",
              " 'could': 68,\n",
              " 'man': 69,\n",
              " 'year': 70,\n",
              " 'islamic': 71,\n",
              " 'time': 72,\n",
              " 'some': 73,\n",
              " 'al': 74,\n",
              " 'according': 75,\n",
              " 'watch': 76,\n",
              " 'over': 77,\n",
              " 'group': 78,\n",
              " 'into': 79,\n",
              " 'so': 80,\n",
              " 'first': 81,\n",
              " 'last': 82,\n",
              " 'being': 83,\n",
              " 'just': 84,\n",
              " 'u': 85,\n",
              " 's': 86,\n",
              " '—': 87,\n",
              " 'government': 88,\n",
              " 'police': 89,\n",
              " 'syria': 90,\n",
              " 'two': 91,\n",
              " 'reports': 92,\n",
              " 'them': 93,\n",
              " 'reported': 94,\n",
              " 'any': 95,\n",
              " 'while': 96,\n",
              " 'other': 97,\n",
              " 'us': 98,\n",
              " 'before': 99,\n",
              " 'like': 100,\n",
              " 'than': 101,\n",
              " 'then': 102,\n",
              " 'media': 103,\n",
              " 'can': 104,\n",
              " 'kim': 105,\n",
              " 'now': 106,\n",
              " 'north': 107,\n",
              " 'story': 108,\n",
              " 'report': 109,\n",
              " 'may': 110,\n",
              " 'where': 111,\n",
              " 'iraq': 112,\n",
              " 'american': 113,\n",
              " 'my': 114,\n",
              " 'even': 115,\n",
              " 'made': 116,\n",
              " 'because': 117,\n",
              " 'says': 118,\n",
              " 'against': 119,\n",
              " 'do': 120,\n",
              " 'since': 121,\n",
              " 'killed': 122,\n",
              " 'only': 123,\n",
              " 'old': 124,\n",
              " 'foley': 125,\n",
              " 'security': 126,\n",
              " 'officials': 127,\n",
              " 'our': 128,\n",
              " 'three': 129,\n",
              " 'militants': 130,\n",
              " 'city': 131,\n",
              " 'say': 132,\n",
              " 'years': 133,\n",
              " 'off': 134,\n",
              " 'how': 135,\n",
              " 'back': 136,\n",
              " 'border': 137,\n",
              " 'during': 138,\n",
              " 'name': 139,\n",
              " 'around': 140,\n",
              " 'another': 141,\n",
              " 'still': 142,\n",
              " 'twitter': 143,\n",
              " 'get': 144,\n",
              " 'official': 145,\n",
              " 'including': 146,\n",
              " 'many': 147,\n",
              " '000': 148,\n",
              " 'world': 149,\n",
              " 'brown': 150,\n",
              " \"it's\": 151,\n",
              " 'family': 152,\n",
              " 'air': 153,\n",
              " 'near': 154,\n",
              " 'through': 155,\n",
              " 'see': 156,\n",
              " 'mr': 157,\n",
              " 'week': 158,\n",
              " 'those': 159,\n",
              " 'military': 160,\n",
              " 'under': 161,\n",
              " 'post': 162,\n",
              " \"'\": 163,\n",
              " 'confirmed': 164,\n",
              " 'did': 165,\n",
              " 'day': 166,\n",
              " 'however': 167,\n",
              " 'found': 168,\n",
              " 'most': 169,\n",
              " 'statement': 170,\n",
              " 'left': 171,\n",
              " 'death': 172,\n",
              " 'iraqi': 173,\n",
              " 'house': 174,\n",
              " 'your': 175,\n",
              " 'claims': 176,\n",
              " 'life': 177,\n",
              " 'leader': 178,\n",
              " 'boko': 179,\n",
              " 'jong': 180,\n",
              " 'very': 181,\n",
              " 'going': 182,\n",
              " 'released': 183,\n",
              " 'british': 184,\n",
              " 'obama': 185,\n",
              " 'it’s': 186,\n",
              " 'went': 187,\n",
              " 'fighters': 188,\n",
              " 'down': 189,\n",
              " '–': 190,\n",
              " '2014': 191,\n",
              " 'forces': 192,\n",
              " 'haram': 193,\n",
              " 'know': 194,\n",
              " 'tuesday': 195,\n",
              " 'reportedly': 196,\n",
              " 'me': 197,\n",
              " 'known': 198,\n",
              " 'service': 199,\n",
              " 'girls': 200,\n",
              " 'month': 201,\n",
              " 'well': 202,\n",
              " 'make': 203,\n",
              " 'ebola': 204,\n",
              " 'these': 205,\n",
              " 'way': 206,\n",
              " 'days': 207,\n",
              " 'president': 208,\n",
              " 'source': 209,\n",
              " 'release': 210,\n",
              " 'woman': 211,\n",
              " 'public': 212,\n",
              " 'journalist': 213,\n",
              " 'times': 214,\n",
              " 'taken': 215,\n",
              " 'kurdish': 216,\n",
              " 'least': 217,\n",
              " 'seen': 218,\n",
              " 'monday': 219,\n",
              " 'part': 220,\n",
              " 'next': 221,\n",
              " 'syrian': 222,\n",
              " 'later': 223,\n",
              " 'several': 224,\n",
              " 'shooting': 225,\n",
              " 'believed': 226,\n",
              " 'press': 227,\n",
              " 'shot': 228,\n",
              " 'health': 229,\n",
              " 'town': 230,\n",
              " 'company': 231,\n",
              " 'took': 232,\n",
              " 'information': 233,\n",
              " 'attack': 234,\n",
              " 'heard': 235,\n",
              " 'posted': 236,\n",
              " 'saying': 237,\n",
              " 'war': 238,\n",
              " 'six': 239,\n",
              " '10': 240,\n",
              " 'claimed': 241,\n",
              " 'hospital': 242,\n",
              " 'used': 243,\n",
              " 'intelligence': 244,\n",
              " 'such': 245,\n",
              " 'sources': 246,\n",
              " 'missing': 247,\n",
              " 'michael': 248,\n",
              " 'site': 249,\n",
              " 'york': 250,\n",
              " 'photo': 251,\n",
              " 'long': 252,\n",
              " 'korean': 253,\n",
              " 'never': 254,\n",
              " 'local': 255,\n",
              " 'something': 256,\n",
              " 'shots': 257,\n",
              " 'son': 258,\n",
              " 'show': 259,\n",
              " 'home': 260,\n",
              " 'come': 261,\n",
              " 'think': 262,\n",
              " 'wednesday': 263,\n",
              " 'high': 264,\n",
              " 'though': 265,\n",
              " 'john': 266,\n",
              " 'ago': 267,\n",
              " 'added': 268,\n",
              " 'much': 269,\n",
              " 'night': 270,\n",
              " 'both': 271,\n",
              " 'called': 272,\n",
              " 'captured': 273,\n",
              " 'country': 274,\n",
              " 'same': 275,\n",
              " 'facebook': 276,\n",
              " '12': 277,\n",
              " 'number': 278,\n",
              " 'officer': 279,\n",
              " 'take': 280,\n",
              " 'former': 281,\n",
              " 'inside': 282,\n",
              " 'between': 283,\n",
              " 'earlier': 284,\n",
              " 'held': 285,\n",
              " 'right': 286,\n",
              " 'un': 287,\n",
              " '2': 288,\n",
              " 'father': 289,\n",
              " 'james': 290,\n",
              " 'based': 291,\n",
              " 'online': 292,\n",
              " 'million': 293,\n",
              " 'thomas': 294,\n",
              " 'go': 295,\n",
              " 'white': 296,\n",
              " 'social': 297,\n",
              " 'work': 298,\n",
              " 'office': 299,\n",
              " 'com': 300,\n",
              " 'wilson': 301,\n",
              " 'national': 302,\n",
              " 'head': 303,\n",
              " '1': 304,\n",
              " 'cnn': 305,\n",
              " 'control': 306,\n",
              " 'friends': 307,\n",
              " 'real': 308,\n",
              " 'daily': 309,\n",
              " 'across': 310,\n",
              " 'spokesman': 311,\n",
              " 'recent': 312,\n",
              " 'use': 313,\n",
              " 'set': 314,\n",
              " '2012': 315,\n",
              " 'should': 316,\n",
              " 'yet': 317,\n",
              " 'area': 318,\n",
              " 'person': 319,\n",
              " 'front': 320,\n",
              " 'came': 321,\n",
              " 'mosul': 322,\n",
              " 'past': 323,\n",
              " '“the': 324,\n",
              " 'put': 325,\n",
              " 'members': 326,\n",
              " 'united': 327,\n",
              " 'today': 328,\n",
              " 'airstrikes': 329,\n",
              " 'website': 330,\n",
              " 'appears': 331,\n",
              " 'youtube': 332,\n",
              " 'thought': 333,\n",
              " 'militant': 334,\n",
              " 'article': 335,\n",
              " 'states': 336,\n",
              " 'international': 337,\n",
              " '11': 338,\n",
              " 'appeared': 339,\n",
              " 'recording': 340,\n",
              " 'asked': 341,\n",
              " 'until': 342,\n",
              " 'dead': 343,\n",
              " 'shows': 344,\n",
              " 'might': 345,\n",
              " 'street': 346,\n",
              " 'korea': 347,\n",
              " 'south': 348,\n",
              " 'few': 349,\n",
              " 'four': 350,\n",
              " 'claim': 351,\n",
              " '“i': 352,\n",
              " 'months': 353,\n",
              " 'fact': 354,\n",
              " 'gold': 355,\n",
              " 'case': 356,\n",
              " '2015': 357,\n",
              " 'second': 358,\n",
              " 'help': 359,\n",
              " 'london': 360,\n",
              " 'want': 361,\n",
              " 'parliament': 362,\n",
              " 'end': 363,\n",
              " 'good': 364,\n",
              " 'working': 365,\n",
              " 'died': 366,\n",
              " 'whether': 367,\n",
              " 'away': 368,\n",
              " 'capital': 369,\n",
              " 'washington': 370,\n",
              " 'using': 371,\n",
              " 'comment': 372,\n",
              " 'emwazi': 373,\n",
              " 'fired': 374,\n",
              " 'wrote': 375,\n",
              " 'early': 376,\n",
              " 'likely': 377,\n",
              " 'building': 378,\n",
              " 'each': 379,\n",
              " 'tv': 380,\n",
              " 'jobs': 381,\n",
              " 'own': 382,\n",
              " 'department': 383,\n",
              " 'weeks': 384,\n",
              " 'place': 385,\n",
              " 'thursday': 386,\n",
              " 'message': 387,\n",
              " 'again': 388,\n",
              " 'announced': 389,\n",
              " 'recently': 390,\n",
              " 'audio': 391,\n",
              " 'making': 392,\n",
              " 'weapons': 393,\n",
              " 'hit': 394,\n",
              " 'following': 395,\n",
              " 'car': 396,\n",
              " 'got': 397,\n",
              " 'kidnapped': 398,\n",
              " 'friday': 399,\n",
              " 'school': 400,\n",
              " 'store': 401,\n",
              " 'students': 402,\n",
              " 'find': 403,\n",
              " 'really': 404,\n",
              " 'given': 405,\n",
              " 'already': 406,\n",
              " '9': 407,\n",
              " 'september': 408,\n",
              " 'canadian': 409,\n",
              " 'august': 410,\n",
              " 'god': 411,\n",
              " 'young': 412,\n",
              " 'lot': 413,\n",
              " 'trying': 414,\n",
              " 'allegedly': 415,\n",
              " 'nigerian': 416,\n",
              " 'men': 417,\n",
              " '“we': 418,\n",
              " 'does': 419,\n",
              " '2011': 420,\n",
              " 'incident': 421,\n",
              " 'here': 422,\n",
              " 'women': 423,\n",
              " 'hands': 424,\n",
              " 'late': 425,\n",
              " 'five': 426,\n",
              " '2013': 427,\n",
              " 'attacks': 428,\n",
              " 'image': 429,\n",
              " 'led': 430,\n",
              " 'videos': 431,\n",
              " 'coming': 432,\n",
              " 'fighting': 433,\n",
              " 'west': 434,\n",
              " 'true': 435,\n",
              " 'alleged': 436,\n",
              " '5': 437,\n",
              " 'iphone': 438,\n",
              " 'internet': 439,\n",
              " 'further': 440,\n",
              " 'actually': 441,\n",
              " 'why': 442,\n",
              " 'comes': 443,\n",
              " 'sunday': 444,\n",
              " 'reporting': 445,\n",
              " 'newspaper': 446,\n",
              " 'rumors': 447,\n",
              " 'black': 448,\n",
              " 'whose': 449,\n",
              " 'terror': 450,\n",
              " 'page': 451,\n",
              " 'outside': 452,\n",
              " 'spider': 453,\n",
              " 'morning': 454,\n",
              " 'force': 455,\n",
              " 'authorities': 456,\n",
              " 'director': 457,\n",
              " 'himself': 458,\n",
              " 'taking': 459,\n",
              " 'believe': 460,\n",
              " 'wife': 461,\n",
              " 'big': 462,\n",
              " 'fire': 463,\n",
              " 'friend': 464,\n",
              " 'children': 465,\n",
              " 'medical': 466,\n",
              " 'too': 467,\n",
              " 'strikes': 468,\n",
              " 'david': 469,\n",
              " 'apparently': 470,\n",
              " 'airport': 471,\n",
              " 'full': 472,\n",
              " 'film': 473,\n",
              " 'free': 474,\n",
              " 'identified': 475,\n",
              " 'live': 476,\n",
              " 'baghdadi': 477,\n",
              " 'happened': 478,\n",
              " 'terrorist': 479,\n",
              " 'without': 480,\n",
              " 'began': 481,\n",
              " 'doctors': 482,\n",
              " 'islam': 483,\n",
              " 'among': 484,\n",
              " 'texas': 485,\n",
              " 'fake': 486,\n",
              " 'via': 487,\n",
              " 'named': 488,\n",
              " 'point': 489,\n",
              " 'face': 490,\n",
              " 'anyone': 491,\n",
              " '20': 492,\n",
              " 'decided': 493,\n",
              " 'close': 494,\n",
              " 'far': 495,\n",
              " 'hoax': 496,\n",
              " 'marijuana': 497,\n",
              " 'despite': 498,\n",
              " 'large': 499,\n",
              " 'small': 500,\n",
              " 'account': 501,\n",
              " 'don’t': 502,\n",
              " 'kobani': 503,\n",
              " 'started': 504,\n",
              " 'law': 505,\n",
              " 'chief': 506,\n",
              " 'confirm': 507,\n",
              " 'food': 508,\n",
              " 'little': 509,\n",
              " 'body': 510,\n",
              " 'ever': 511,\n",
              " 'look': 512,\n",
              " 'saturday': 513,\n",
              " 'event': 514,\n",
              " 'power': 515,\n",
              " 'amazon': 516,\n",
              " '6': 517,\n",
              " 'prime': 518,\n",
              " 'boy': 519,\n",
              " 'money': 520,\n",
              " 'clear': 521,\n",
              " 'ferguson': 522,\n",
              " 'possible': 523,\n",
              " 'steve': 524,\n",
              " 'western': 525,\n",
              " 'rosenberg': 526,\n",
              " 'gave': 527,\n",
              " 'co': 528,\n",
              " 'revealed': 529,\n",
              " 'details': 530,\n",
              " 'sure': 531,\n",
              " 'meteorite': 532,\n",
              " 'associated': 533,\n",
              " 'hours': 534,\n",
              " 'mother': 535,\n",
              " 'aid': 536,\n",
              " 'caught': 537,\n",
              " 'device': 538,\n",
              " 'child': 539,\n",
              " 'army': 540,\n",
              " 'become': 541,\n",
              " 'instead': 542,\n",
              " 'expected': 543,\n",
              " 'start': 544,\n",
              " 'northern': 545,\n",
              " 'stop': 546,\n",
              " 'born': 547,\n",
              " 'although': 548,\n",
              " 'enough': 549,\n",
              " 'abu': 550,\n",
              " 'able': 551,\n",
              " 'smith': 552,\n",
              " 'daughter': 553,\n",
              " 'once': 554,\n",
              " 'due': 555,\n",
              " 'minister': 556,\n",
              " 'ottawa': 557,\n",
              " 'interview': 558,\n",
              " 'saw': 559,\n",
              " 'showed': 560,\n",
              " 'dog': 561,\n",
              " 'foreign': 562,\n",
              " 'things': 563,\n",
              " 'bale': 564,\n",
              " 'mark': 565,\n",
              " 'thing': 566,\n",
              " '40': 567,\n",
              " 'cases': 568,\n",
              " 'open': 569,\n",
              " '18': 570,\n",
              " 'fight': 571,\n",
              " 'human': 572,\n",
              " 'ground': 573,\n",
              " 'middle': 574,\n",
              " 'officers': 575,\n",
              " 'de': 576,\n",
              " 'along': 577,\n",
              " '100': 578,\n",
              " 'soldiers': 579,\n",
              " 'order': 580,\n",
              " 'turned': 581,\n",
              " 'fbi': 582,\n",
              " 'parents': 583,\n",
              " 'call': 584,\n",
              " 'arrested': 585,\n",
              " 'paul': 586,\n",
              " 'users': 587,\n",
              " 'almost': 588,\n",
              " 'pause': 589,\n",
              " 'others': 590,\n",
              " 'violence': 591,\n",
              " 'role': 592,\n",
              " 'looking': 593,\n",
              " '4': 594,\n",
              " 'party': 595,\n",
              " 'operation': 596,\n",
              " 'agency': 597,\n",
              " 'secret': 598,\n",
              " '8': 599,\n",
              " 'conference': 600,\n",
              " 'investigation': 601,\n",
              " 'give': 602,\n",
              " 'hostages': 603,\n",
              " 'change': 604,\n",
              " 'tour': 605,\n",
              " 'ministry': 606,\n",
              " 'having': 607,\n",
              " 'read': 608,\n",
              " 'showing': 609,\n",
              " 'heart': 610,\n",
              " 'behind': 611,\n",
              " 'rights': 612,\n",
              " 'policy': 613,\n",
              " 'probably': 614,\n",
              " 'east': 615,\n",
              " 'beheading': 616,\n",
              " 'center': 617,\n",
              " 'pope': 618,\n",
              " 'immediately': 619,\n",
              " 'run': 620,\n",
              " 'senior': 621,\n",
              " 'blumenthal': 622,\n",
              " 'israeli': 623,\n",
              " 'every': 624,\n",
              " '3': 625,\n",
              " 'support': 626,\n",
              " 'macbook': 627,\n",
              " 'star': 628,\n",
              " 'banksy': 629,\n",
              " 'brother': 630,\n",
              " 'currently': 631,\n",
              " 'libya': 632,\n",
              " 'april': 633,\n",
              " 'centre': 634,\n",
              " 'nigeria': 635,\n",
              " 'reuters': 636,\n",
              " 'soon': 637,\n",
              " 'decision': 638,\n",
              " 'nothing': 639,\n",
              " 'price': 640,\n",
              " 'holding': 641,\n",
              " 'photos': 642,\n",
              " 'november': 643,\n",
              " 'am': 644,\n",
              " 'evidence': 645,\n",
              " 'deal': 646,\n",
              " \"don't\": 647,\n",
              " 'follow': 648,\n",
              " 'isil': 649,\n",
              " 'witnesses': 650,\n",
              " 'move': 651,\n",
              " 'top': 652,\n",
              " 'launch': 653,\n",
              " 'sotloff': 654,\n",
              " 'kind': 655,\n",
              " 'hunter': 656,\n",
              " 'comcast': 657,\n",
              " 'level': 658,\n",
              " 'water': 659,\n",
              " 'animals': 660,\n",
              " 'murder': 661,\n",
              " 'thousands': 662,\n",
              " 'hand': 663,\n",
              " 'names': 664,\n",
              " 'skin': 665,\n",
              " 'wanted': 666,\n",
              " '200': 667,\n",
              " 'previously': 668,\n",
              " 'staff': 669,\n",
              " 'francis': 670,\n",
              " 'woods': 671,\n",
              " 'major': 672,\n",
              " 'girl': 673,\n",
              " 'phone': 674,\n",
              " 'killing': 675,\n",
              " 'spice': 676,\n",
              " 'actor': 677,\n",
              " 'carried': 678,\n",
              " 'done': 679,\n",
              " 'version': 680,\n",
              " 'situation': 681,\n",
              " 'january': 682,\n",
              " 'america': 683,\n",
              " '22': 684,\n",
              " '13': 685,\n",
              " 'seems': 686,\n",
              " 'wearing': 687,\n",
              " 'play': 688,\n",
              " 'jihadi': 689,\n",
              " 'bibeau': 690,\n",
              " 'love': 691,\n",
              " 'tell': 692,\n",
              " 'terrorists': 693,\n",
              " 'inch': 694,\n",
              " 'general': 695,\n",
              " 'continued': 696,\n",
              " 'described': 697,\n",
              " 'spoke': 698,\n",
              " 'campaign': 699,\n",
              " 'google': 700,\n",
              " 'attorney': 701,\n",
              " 'condition': 702,\n",
              " 'need': 703,\n",
              " 'mail': 704,\n",
              " 'images': 705,\n",
              " 'suspected': 706,\n",
              " 'within': 707,\n",
              " 'leave': 708,\n",
              " 'lin': 709,\n",
              " \"didn't\": 710,\n",
              " 'must': 711,\n",
              " 'weekend': 712,\n",
              " 'virus': 713,\n",
              " 'october': 714,\n",
              " 'that’s': 715,\n",
              " 'organization': 716,\n",
              " 'didn’t': 717,\n",
              " 'plans': 718,\n",
              " 'reached': 719,\n",
              " 'memorial': 720,\n",
              " 'returned': 721,\n",
              " 'someone': 722,\n",
              " 'best': 723,\n",
              " 'contact': 724,\n",
              " 'user': 725,\n",
              " 'continue': 726,\n",
              " 'residents': 727,\n",
              " '30': 728,\n",
              " 'talks': 729,\n",
              " 'threat': 730,\n",
              " 'masked': 731,\n",
              " 'different': 732,\n",
              " 'identity': 733,\n",
              " 'uk': 734,\n",
              " 'suspect': 735,\n",
              " 'running': 736,\n",
              " 'issue': 737,\n",
              " 'homeless': 738,\n",
              " 'outlets': 739,\n",
              " 'zehaf': 740,\n",
              " 'planes': 741,\n",
              " 'picture': 742,\n",
              " 'doing': 743,\n",
              " 'related': 744,\n",
              " 'detained': 745,\n",
              " 'problem': 746,\n",
              " 'extremist': 747,\n",
              " 'islamist': 748,\n",
              " 'movie': 749,\n",
              " 'schoolgirls': 750,\n",
              " 'earth': 751,\n",
              " 'edition': 752,\n",
              " 'often': 753,\n",
              " 'english': 754,\n",
              " '24': 755,\n",
              " 'action': 756,\n",
              " 'remains': 757,\n",
              " 'living': 758,\n",
              " 'received': 759,\n",
              " 'authenticity': 760,\n",
              " 'date': 761,\n",
              " 'sister': 762,\n",
              " 'drug': 763,\n",
              " 'johnson': 764,\n",
              " 'st': 765,\n",
              " 'qaeda': 766,\n",
              " 'business': 767,\n",
              " 'everything': 768,\n",
              " 'pumpkin': 769,\n",
              " 'university': 770,\n",
              " 'pentagon': 771,\n",
              " 'trip': 772,\n",
              " 'keep': 773,\n",
              " 'pro': 774,\n",
              " 'vehicle': 775,\n",
              " 'important': 776,\n",
              " 'africa': 777,\n",
              " 'saudi': 778,\n",
              " 'crater': 779,\n",
              " 'getting': 780,\n",
              " '7': 781,\n",
              " 'dozens': 782,\n",
              " 'central': 783,\n",
              " '15': 784,\n",
              " 'latest': 785,\n",
              " 'impact': 786,\n",
              " 'similar': 787,\n",
              " 'private': 788,\n",
              " 'scene': 789,\n",
              " 'boston': 790,\n",
              " 'meeting': 791,\n",
              " 'speaking': 792,\n",
              " 'ceasefire': 793,\n",
              " \"that's\": 794,\n",
              " 'lebanese': 795,\n",
              " 'february': 796,\n",
              " 'footage': 797,\n",
              " 'job': 798,\n",
              " 'vice': 799,\n",
              " 'mohammed': 800,\n",
              " 'camera': 801,\n",
              " 'services': 802,\n",
              " 'member': 803,\n",
              " 'birth': 804,\n",
              " '25': 805,\n",
              " 'great': 806,\n",
              " 'kobane': 807,\n",
              " 'false': 808,\n",
              " 'low': 809,\n",
              " 'quickly': 810,\n",
              " 'steven': 811,\n",
              " 'rumor': 812,\n",
              " 'southern': 813,\n",
              " 'court': 814,\n",
              " 'hill': 815,\n",
              " 'experts': 816,\n",
              " 'network': 817,\n",
              " 'became': 818,\n",
              " 'update': 819,\n",
              " 'launched': 820,\n",
              " 'suffering': 821,\n",
              " 'nearly': 822,\n",
              " 'region': 823,\n",
              " 'december': 824,\n",
              " 'spread': 825,\n",
              " 'caused': 826,\n",
              " 'female': 827,\n",
              " 'knew': 828,\n",
              " 'removed': 829,\n",
              " 'sex': 830,\n",
              " 'bbc': 831,\n",
              " 'spent': 832,\n",
              " 'justice': 833,\n",
              " 'alive': 834,\n",
              " 'station': 835,\n",
              " 'stopped': 836,\n",
              " 'm': 837,\n",
              " 'published': 838,\n",
              " 'less': 839,\n",
              " 'shared': 840,\n",
              " 'dropped': 841,\n",
              " 'baby': 842,\n",
              " 'space': 843,\n",
              " 'mass': 844,\n",
              " 'seized': 845,\n",
              " 'gang': 846,\n",
              " 'soldier': 847,\n",
              " 'comments': 848,\n",
              " 'scotland': 849,\n",
              " 'aircraft': 850,\n",
              " 'vogue': 851,\n",
              " 'claiming': 852,\n",
              " 'main': 853,\n",
              " '14': 854,\n",
              " 'anything': 855,\n",
              " 'march': 856,\n",
              " '31': 857,\n",
              " 'met': 858,\n",
              " 'felt': 859,\n",
              " 'seven': 860,\n",
              " 'june': 861,\n",
              " 'series': 862,\n",
              " 'groups': 863,\n",
              " 'multiple': 864,\n",
              " 'line': 865,\n",
              " 'age': 866,\n",
              " 'josh': 867,\n",
              " 'christian': 868,\n",
              " 'customers': 869,\n",
              " 'game': 870,\n",
              " 'hostage': 871,\n",
              " 'viral': 872,\n",
              " 'muslims': 873,\n",
              " 'leadership': 874,\n",
              " 'minutes': 875,\n",
              " 'available': 876,\n",
              " 'room': 877,\n",
              " 'team': 878,\n",
              " 'jordanian': 879,\n",
              " 'either': 880,\n",
              " 'journalists': 881,\n",
              " 'television': 882,\n",
              " 'lost': 883,\n",
              " 'instagram': 884,\n",
              " '“it': 885,\n",
              " 'denied': 886,\n",
              " 'olsen': 887,\n",
              " 'pyongyang': 888,\n",
              " 'expert': 889,\n",
              " 'market': 890,\n",
              " 'nearby': 891,\n",
              " 'safe': 892,\n",
              " 'guard': 893,\n",
              " 'haines': 894,\n",
              " 'involved': 895,\n",
              " 'followed': 896,\n",
              " 'apartment': 897,\n",
              " 'king': 898,\n",
              " 'makes': 899,\n",
              " '’': 900,\n",
              " 'below': 901,\n",
              " 'tweeted': 902,\n",
              " 'gone': 903,\n",
              " 'door': 904,\n",
              " 'adding': 905,\n",
              " 'mexico': 906,\n",
              " 'vickers': 907,\n",
              " 'lives': 908,\n",
              " 'leading': 909,\n",
              " 'perhaps': 910,\n",
              " 'sent': 911,\n",
              " 'book': 912,\n",
              " 'arms': 913,\n",
              " 'experience': 914,\n",
              " 'bit': 915,\n",
              " 'blog': 916,\n",
              " 'single': 917,\n",
              " 'sell': 918,\n",
              " 'strike': 919,\n",
              " 'cause': 920,\n",
              " 'fox': 921,\n",
              " 'pretty': 922,\n",
              " 'stolen': 923,\n",
              " 'miles': 924,\n",
              " 'verified': 925,\n",
              " \"he's\": 926,\n",
              " 'side': 927,\n",
              " 'discovered': 928,\n",
              " 'key': 929,\n",
              " 'percent': 930,\n",
              " 'everyone': 931,\n",
              " 'godane': 932,\n",
              " 'sold': 933,\n",
              " 'spokesperson': 934,\n",
              " 'sorkin': 935,\n",
              " 'web': 936,\n",
              " 'ran': 937,\n",
              " 'surgery': 938,\n",
              " 'defense': 939,\n",
              " 'magazine': 940,\n",
              " 'charge': 941,\n",
              " 'americans': 942,\n",
              " 'pga': 943,\n",
              " 'areas': 944,\n",
              " 'recorded': 945,\n",
              " 'coalition': 946,\n",
              " 'doesn’t': 947,\n",
              " 'shekau': 948,\n",
              " 'hear': 949,\n",
              " 'victims': 950,\n",
              " 'moment': 951,\n",
              " 'yo': 952,\n",
              " 'means': 953,\n",
              " 'capture': 954,\n",
              " 'symptoms': 955,\n",
              " \"apple's\": 956,\n",
              " 'created': 957,\n",
              " 'turkey': 958,\n",
              " 'worked': 959,\n",
              " 'tape': 960,\n",
              " 'happen': 961,\n",
              " 'community': 962,\n",
              " 'blood': 963,\n",
              " 'issued': 964,\n",
              " 'mike': 965,\n",
              " 'calls': 966,\n",
              " 'original': 967,\n",
              " 'strong': 968,\n",
              " 'arrest': 969,\n",
              " 'hard': 970,\n",
              " 'act': 971,\n",
              " 'fighter': 972,\n",
              " 'themselves': 973,\n",
              " 'model': 974,\n",
              " 'july': 975,\n",
              " 'question': 976,\n",
              " 'joined': 977,\n",
              " 'bary': 978,\n",
              " 'abducted': 979,\n",
              " 'asteroid': 980,\n",
              " \"doesn't\": 981,\n",
              " 'disease': 982,\n",
              " 'kurds': 983,\n",
              " 'cook': 984,\n",
              " 'israel': 985,\n",
              " 'cost': 986,\n",
              " 'appear': 987,\n",
              " 'offer': 988,\n",
              " 'jihadist': 989,\n",
              " 'box': 990,\n",
              " 'stories': 991,\n",
              " 'return': 992,\n",
              " 'reporter': 993,\n",
              " 'cut': 994,\n",
              " 'worker': 995,\n",
              " 'course': 996,\n",
              " 'fall': 997,\n",
              " 'pictures': 998,\n",
              " 'brought': 999,\n",
              " 'citing': 1000,\n",
              " ...}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nEe2G_AmOei-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "headlines=tokenizer.fit_on_texts(df['Headline'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CHAsvUJQ9dY8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wordindex=tokenizer.word_index"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T1ZmUAns9hC5",
        "colab_type": "code",
        "outputId": "0329bb1d-4ff0-468b-e017-5f0dc063a4bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(wordindex)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "27873"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "omptHX-JpBsN"
      },
      "source": [
        "#### fit_on_texts() gives the following attributes in the output as given [here](https://faroit.github.io/keras-docs/1.2.2/preprocessing/text/).\n",
        "\n",
        "* **word_counts:** dictionary mapping words (str) to the number of times they appeared on during fit. Only set after fit_on_texts was called.\n",
        "\n",
        "* **word_docs:** dictionary mapping words (str) to the number of documents/texts they appeared on during fit. Only set after fit_on_texts was called.\n",
        "\n",
        "* **word_index:** dictionary mapping words (str) to their rank/index (int). Only set after fit_on_texts was called.\n",
        "\n",
        "* **document_count:** int. Number of documents (texts/sequences) the tokenizer was trained on. Only set after fit_on_texts or fit_on_sequences was called.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "SHnsT2sTtFAA"
      },
      "source": [
        "### Now, tokenize the sentences using nltk sent_tokenize() and encode the senteces with the ids we got form the above `t.word_index`\n",
        "\n",
        "Initialise 2 lists with names `texts` and `articles`.\n",
        "\n",
        "```\n",
        "texts = [] to store text of article as it is.\n",
        "\n",
        "articles = [] split the above text into a list of sentences.\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EBoyzUOhjQyJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.tokenize import sent_tokenize"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "abByX-qDb7Mv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "texts=[]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "USXI1IJZjW7p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "texts = df['articleBody']\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O1bQVYOcb1nG",
        "colab_type": "code",
        "outputId": "9db9c7e2-54a5-4c0f-8dc4-c55845b59d9f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        }
      },
      "source": [
        "texts.count"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method Series.count of 0        A small meteorite crashed into a wooded area i...\n",
              "1        A small meteorite crashed into a wooded area i...\n",
              "2        A small meteorite crashed into a wooded area i...\n",
              "3        A small meteorite crashed into a wooded area i...\n",
              "4        A small meteorite crashed into a wooded area i...\n",
              "                               ...                        \n",
              "49967    ANN ARBOR, Mich. – A pizza delivery man in Mic...\n",
              "49968    ANN ARBOR, Mich. – A pizza delivery man in Mic...\n",
              "49969    ANN ARBOR, Mich. – A pizza delivery man in Mic...\n",
              "49970    ANN ARBOR, Mich. – A pizza delivery man in Mic...\n",
              "49971    ANN ARBOR, Mich. – A pizza delivery man in Mic...\n",
              "Name: articleBody, Length: 49972, dtype: object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fvl9ZUiqyTvA",
        "colab_type": "code",
        "outputId": "358b4592-6573-40cd-bdd9-15c4fc0b7801",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "texts[100]"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'At least 25 suspected Boko Haram insurgents were killed in clashes between soldiers and the Islamist militants in northeast Nigeria and five civilians were killed in fighting elsewhere in the region, a military source and residents said on Monday.\\n\\nA ceasefire agreement between Boko Haram and the Nigerian government was expected to lead to the liberation of more than 200 schoolgirls kidnapped by the militants six months ago, and talks were due to continue in neighbouring Chad on Monday.\\n\\nBoko Haram has not confirmed the truce and there have been at least six attacks over the weekend – blamed by security sources on the insurgents – that have killed several dozen people since the announcement of the ceasefire.\\n\\nA government spokesman has said that the fighting on Sunday may be the work of criminal gangs in the lawless region.\\n\\nAn army officer, who requested anonymity, said the militants tried to enter the town of Damboa late on Sunday through Alagarno, a Boko Haram hideout, but soldiers fought them off. “Our men gunned down 25 of the insurgents because they would have entered Damboa and unleashed more terror on the town that is just picking up from its ruins,” the officer said.\\n\\nHe said an armoured vehicle and some arms were recovered from the insurgents.\\n\\nDamboa, a garrison town near the border with Cameroon, has been the site of fierce fighting between the militants and Nigerian forces for months. The insurgents sacked the town in July but were driven out by an army counter-offensive.\\n\\nA member of pro-government Civilian Joint Task Force vigilantes, Mohammed Haruna, said of clashes on Sunday, “Two of our members came to [the town of] Biu this morning from Damboa and said the soldiers engaged Boko Haram yesterday and the battle lasted till about midnight.”\\n\\nSeparately, Maiduguri resident Andrew Tada, said the insurgents killed five people in Gava, a hilly town in Gwoza Local Government Area not far from Damboa.\\n\\nTada said his brother in Gava was lucky to have escaped to the top of a mountain.\\n\\n“My brother is still there now with other relatives, women and children,” he told Reuters after speaking with his brother on the phone.\\n\\n“They [the militants] came yesterday [Sunday] while people were scouting for food at the foot of the mountain. When the insurgents sighted our people, they pursued them and slaughtered five,” Tada said.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U_y65vtzcD7O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sents=[]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c-AAAAYcsC-g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sents = texts.apply(sent_tokenize)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DDOZByDPsQnF",
        "colab_type": "code",
        "outputId": "6c594b69-e5bd-4439-9c27-3793970bb18a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "source": [
        "sents[100]"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['At least 25 suspected Boko Haram insurgents were killed in clashes between soldiers and the Islamist militants in northeast Nigeria and five civilians were killed in fighting elsewhere in the region, a military source and residents said on Monday.',\n",
              " 'A ceasefire agreement between Boko Haram and the Nigerian government was expected to lead to the liberation of more than 200 schoolgirls kidnapped by the militants six months ago, and talks were due to continue in neighbouring Chad on Monday.',\n",
              " 'Boko Haram has not confirmed the truce and there have been at least six attacks over the weekend – blamed by security sources on the insurgents – that have killed several dozen people since the announcement of the ceasefire.',\n",
              " 'A government spokesman has said that the fighting on Sunday may be the work of criminal gangs in the lawless region.',\n",
              " 'An army officer, who requested anonymity, said the militants tried to enter the town of Damboa late on Sunday through Alagarno, a Boko Haram hideout, but soldiers fought them off.',\n",
              " '“Our men gunned down 25 of the insurgents because they would have entered Damboa and unleashed more terror on the town that is just picking up from its ruins,” the officer said.',\n",
              " 'He said an armoured vehicle and some arms were recovered from the insurgents.',\n",
              " 'Damboa, a garrison town near the border with Cameroon, has been the site of fierce fighting between the militants and Nigerian forces for months.',\n",
              " 'The insurgents sacked the town in July but were driven out by an army counter-offensive.',\n",
              " 'A member of pro-government Civilian Joint Task Force vigilantes, Mohammed Haruna, said of clashes on Sunday, “Two of our members came to [the town of] Biu this morning from Damboa and said the soldiers engaged Boko Haram yesterday and the battle lasted till about midnight.”\\n\\nSeparately, Maiduguri resident Andrew Tada, said the insurgents killed five people in Gava, a hilly town in Gwoza Local Government Area not far from Damboa.',\n",
              " 'Tada said his brother in Gava was lucky to have escaped to the top of a mountain.',\n",
              " '“My brother is still there now with other relatives, women and children,” he told Reuters after speaking with his brother on the phone.',\n",
              " '“They [the militants] came yesterday [Sunday] while people were scouting for food at the foot of the mountain.',\n",
              " 'When the insurgents sighted our people, they pursued them and slaughtered five,” Tada said.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "koTVJjoO6P78"
      },
      "source": [
        "## Check 2:\n",
        "\n",
        "first element of texts and articles should be as given below. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3mWBW99p5UW9",
        "outputId": "f39d9f70-4eef-4d6e-e988-296f6cad7b08",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "texts[0]"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'A small meteorite crashed into a wooded area in Nicaragua\\'s capital of Managua overnight, the government said Sunday. Residents reported hearing a mysterious boom that left a 16-foot deep crater near the city\\'s airport, the Associated Press reports. \\n\\nGovernment spokeswoman Rosario Murillo said a committee formed by the government to study the event determined it was a \"relatively small\" meteorite that \"appears to have come off an asteroid that was passing close to Earth.\" House-sized asteroid 2014 RC, which measured 60 feet in diameter, skimmed the Earth this weekend, ABC News reports. \\nMurillo said Nicaragua will ask international experts to help local scientists in understanding what happened.\\n\\nThe crater left by the meteorite had a radius of 39 feet and a depth of 16 feet,  said Humberto Saballos, a volcanologist with the Nicaraguan Institute of Territorial Studies who was on the committee. He said it is still not clear if the meteorite disintegrated or was buried.\\n\\nHumberto Garcia, of the Astronomy Center at the National Autonomous University of Nicaragua, said the meteorite could be related to an asteroid that was forecast to pass by the planet Saturday night.\\n\\n\"We have to study it more because it could be ice or rock,\" he said.\\n\\nWilfried Strauch, an adviser to the Institute of Territorial Studies, said it was \"very strange that no one reported a streak of light. We have to ask if anyone has a photo or something.\"\\n\\nLocal residents reported hearing a loud boom Saturday night, but said they didn\\'t see anything strange in the sky.\\n\\n\"I was sitting on my porch and I saw nothing, then all of a sudden I heard a large blast. We thought it was a bomb because we felt an expansive wave,\" Jorge Santamaria told The Associated Press.\\n\\nThe site of the crater is near Managua\\'s international airport and an air force base. Only journalists from state media were allowed to visit it.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "WtIjO3ht5EKA",
        "outputId": "3d0214db-bd76-431b-b120-9dbc04e926ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 318
        }
      },
      "source": [
        "sents[1]"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"A small meteorite crashed into a wooded area in Nicaragua's capital of Managua overnight, the government said Sunday.\",\n",
              " \"Residents reported hearing a mysterious boom that left a 16-foot deep crater near the city's airport, the Associated Press reports.\",\n",
              " 'Government spokeswoman Rosario Murillo said a committee formed by the government to study the event determined it was a \"relatively small\" meteorite that \"appears to have come off an asteroid that was passing close to Earth.\"',\n",
              " 'House-sized asteroid 2014 RC, which measured 60 feet in diameter, skimmed the Earth this weekend, ABC News reports.',\n",
              " 'Murillo said Nicaragua will ask international experts to help local scientists in understanding what happened.',\n",
              " 'The crater left by the meteorite had a radius of 39 feet and a depth of 16 feet,  said Humberto Saballos, a volcanologist with the Nicaraguan Institute of Territorial Studies who was on the committee.',\n",
              " 'He said it is still not clear if the meteorite disintegrated or was buried.',\n",
              " 'Humberto Garcia, of the Astronomy Center at the National Autonomous University of Nicaragua, said the meteorite could be related to an asteroid that was forecast to pass by the planet Saturday night.',\n",
              " '\"We have to study it more because it could be ice or rock,\" he said.',\n",
              " 'Wilfried Strauch, an adviser to the Institute of Territorial Studies, said it was \"very strange that no one reported a streak of light.',\n",
              " 'We have to ask if anyone has a photo or something.\"',\n",
              " \"Local residents reported hearing a loud boom Saturday night, but said they didn't see anything strange in the sky.\",\n",
              " '\"I was sitting on my porch and I saw nothing, then all of a sudden I heard a large blast.',\n",
              " 'We thought it was a bomb because we felt an expansive wave,\" Jorge Santamaria told The Associated Press.',\n",
              " \"The site of the crater is near Managua's international airport and an air force base.\",\n",
              " 'Only journalists from state media were allowed to visit it.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o4b9gglVYewl",
        "colab_type": "code",
        "outputId": "d5e76aa6-0864-4c7c-811b-b27ab13da72f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        }
      },
      "source": [
        "sents.count"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method Series.count of 0        [A small meteorite crashed into a wooded area ...\n",
              "1        [A small meteorite crashed into a wooded area ...\n",
              "2        [A small meteorite crashed into a wooded area ...\n",
              "3        [A small meteorite crashed into a wooded area ...\n",
              "4        [A small meteorite crashed into a wooded area ...\n",
              "                               ...                        \n",
              "49967    [ANN ARBOR, Mich. – A pizza delivery man in Mi...\n",
              "49968    [ANN ARBOR, Mich. – A pizza delivery man in Mi...\n",
              "49969    [ANN ARBOR, Mich. – A pizza delivery man in Mi...\n",
              "49970    [ANN ARBOR, Mich. – A pizza delivery man in Mi...\n",
              "49971    [ANN ARBOR, Mich. – A pizza delivery man in Mi...\n",
              "Name: articleBody, Length: 49972, dtype: object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "fpuRIA7cCfcY"
      },
      "source": [
        "# Now iterate through each article and each sentence to encode the words into ids using t.word_index  [5 marks] \n",
        "\n",
        "Here, to get words from sentence you can use `text_to_word_sequence` from keras preprocessing text.\n",
        "\n",
        "1. Import text_to_word_sequence\n",
        "\n",
        "2. Initialize a variable of shape (no.of articles, MAX_SENTS, MAX_SENT_LENGTH) with name `data` with zeros first (you can use numpy [np.zeros](https://docs.scipy.org/doc/numpy/reference/generated/numpy.zeros.html) to initialize with all zeros)and then update it while iterating through the words and sentences in each article."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YVyClBULCqWj",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.text import text_to_word_sequence"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rDho59E9DLP4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import array \n",
        "import re"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rkCYXKBxEXX3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "data=np.zeros((49972,1000,1000))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yJtOf5_AeOxo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "keras.preprocessing.text.text_to_word_sequence(sents)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VRjrV39jYlio",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "aa39ab8c-f0c5-468d-ee47-07bd40a8edcb"
      },
      "source": [
        "len(sents)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "49972"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F8v50iC3bi_E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 318
        },
        "outputId": "07d719bb-4ff7-4c2a-e291-9184a984e78c"
      },
      "source": [
        "sents[1]"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"A small meteorite crashed into a wooded area in Nicaragua's capital of Managua overnight, the government said Sunday.\",\n",
              " \"Residents reported hearing a mysterious boom that left a 16-foot deep crater near the city's airport, the Associated Press reports.\",\n",
              " 'Government spokeswoman Rosario Murillo said a committee formed by the government to study the event determined it was a \"relatively small\" meteorite that \"appears to have come off an asteroid that was passing close to Earth.\"',\n",
              " 'House-sized asteroid 2014 RC, which measured 60 feet in diameter, skimmed the Earth this weekend, ABC News reports.',\n",
              " 'Murillo said Nicaragua will ask international experts to help local scientists in understanding what happened.',\n",
              " 'The crater left by the meteorite had a radius of 39 feet and a depth of 16 feet,  said Humberto Saballos, a volcanologist with the Nicaraguan Institute of Territorial Studies who was on the committee.',\n",
              " 'He said it is still not clear if the meteorite disintegrated or was buried.',\n",
              " 'Humberto Garcia, of the Astronomy Center at the National Autonomous University of Nicaragua, said the meteorite could be related to an asteroid that was forecast to pass by the planet Saturday night.',\n",
              " '\"We have to study it more because it could be ice or rock,\" he said.',\n",
              " 'Wilfried Strauch, an adviser to the Institute of Territorial Studies, said it was \"very strange that no one reported a streak of light.',\n",
              " 'We have to ask if anyone has a photo or something.\"',\n",
              " \"Local residents reported hearing a loud boom Saturday night, but said they didn't see anything strange in the sky.\",\n",
              " '\"I was sitting on my porch and I saw nothing, then all of a sudden I heard a large blast.',\n",
              " 'We thought it was a bomb because we felt an expansive wave,\" Jorge Santamaria told The Associated Press.',\n",
              " \"The site of the crater is near Managua's international airport and an air force base.\",\n",
              " 'Only journalists from state media were allowed to visit it.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5xv4wAVWeLEf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "outputId": "eb943bf8-2c9e-4b01-f641-eec4bd0a82f8"
      },
      "source": [
        "for i,sublist_sentence in enumerate(sents[0:2]):\n",
        "  #print(sublist_sentence)\n",
        "  for j,sentence in enumerate(sublist_sentence):\n",
        "    #print(sentence.strip())\n",
        "    #if len(sentence.strip()) < 20:\n",
        "    words = text_to_word_sequence(str(sentence))\n",
        "    print(words)\n",
        "    for k,w in enumerate(words):\n",
        "      #if len(w) < 20:\n",
        "      data[i,j,k] = wordindex[w]"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-f13f89b312c3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msublist_sentence\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msents\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m   \u001b[0;31m#print(sublist_sentence)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msentence\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msublist_sentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m#print(sentence.strip())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m#if len(sentence.strip()) < 20:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'sents' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tCZG65OsgObB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 579
        },
        "outputId": "75cb906c-6d78-4eb0-a0b7-d22f02d32bca"
      },
      "source": [
        "for i in sents[0:2]:\n",
        "  #print(i)\n",
        "  for j in i:\n",
        "    #print('This is Sentence:',j)\n",
        "    print('Length :',len(j.strip()))"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length : 117\n",
            "Length : 131\n",
            "Length : 225\n",
            "Length : 115\n",
            "Length : 110\n",
            "Length : 200\n",
            "Length : 75\n",
            "Length : 199\n",
            "Length : 68\n",
            "Length : 135\n",
            "Length : 51\n",
            "Length : 114\n",
            "Length : 89\n",
            "Length : 104\n",
            "Length : 85\n",
            "Length : 59\n",
            "Length : 117\n",
            "Length : 131\n",
            "Length : 225\n",
            "Length : 115\n",
            "Length : 110\n",
            "Length : 200\n",
            "Length : 75\n",
            "Length : 199\n",
            "Length : 68\n",
            "Length : 135\n",
            "Length : 51\n",
            "Length : 114\n",
            "Length : 89\n",
            "Length : 104\n",
            "Length : 85\n",
            "Length : 59\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zj0jwou3-IKA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        },
        "outputId": "a1db92d3-755a-4d5b-9e41-cd0442380b0d"
      },
      "source": [
        "for sentence in sents[:2]:\n",
        "  print(sentence)\n",
        "  if len(sentence.strip()) < 20:\n",
        "    # sent = sentence.strip()\n",
        "    words = text_to_word_sequence(str(sentence))\n",
        "    for w in words:\n",
        "      if len(w) < 20:\n",
        "        if w in wordindex:#tokenizer.word_index:\n",
        "          data[i, j, k] = wordindex[w] #tokenizer.word_index[w]\n",
        "  #   for j,word_ in enumerate(words):\n",
        "  #     if len(j) < 20:\n",
        "\n",
        "  # #short_sents = re.split(sentence)\n",
        "  # for j, sent in enumerate(str(sentence)):\n",
        "  #   print(j,sent)\n",
        "  #   #if len(sent) < 20:\n",
        "  #   if j < 20 and sent.strip():\n",
        "  #     words = text_to_word_sequence(str(sentence))\n",
        "  #     k = 0\n",
        "  #     for w in words:\n",
        "  #       if k < 20:\n",
        "  #         if w in wordindex:#tokenizer.word_index:\n",
        "  #           data[i, j, k] = wordindex[w] #tokenizer.word_index[w]"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[\"A small meteorite crashed into a wooded area in Nicaragua's capital of Managua overnight, the government said Sunday.\", \"Residents reported hearing a mysterious boom that left a 16-foot deep crater near the city's airport, the Associated Press reports.\", 'Government spokeswoman Rosario Murillo said a committee formed by the government to study the event determined it was a \"relatively small\" meteorite that \"appears to have come off an asteroid that was passing close to Earth.\"', 'House-sized asteroid 2014 RC, which measured 60 feet in diameter, skimmed the Earth this weekend, ABC News reports.', 'Murillo said Nicaragua will ask international experts to help local scientists in understanding what happened.', 'The crater left by the meteorite had a radius of 39 feet and a depth of 16 feet,  said Humberto Saballos, a volcanologist with the Nicaraguan Institute of Territorial Studies who was on the committee.', 'He said it is still not clear if the meteorite disintegrated or was buried.', 'Humberto Garcia, of the Astronomy Center at the National Autonomous University of Nicaragua, said the meteorite could be related to an asteroid that was forecast to pass by the planet Saturday night.', '\"We have to study it more because it could be ice or rock,\" he said.', 'Wilfried Strauch, an adviser to the Institute of Territorial Studies, said it was \"very strange that no one reported a streak of light.', 'We have to ask if anyone has a photo or something.\"', \"Local residents reported hearing a loud boom Saturday night, but said they didn't see anything strange in the sky.\", '\"I was sitting on my porch and I saw nothing, then all of a sudden I heard a large blast.', 'We thought it was a bomb because we felt an expansive wave,\" Jorge Santamaria told The Associated Press.', \"The site of the crater is near Managua's international airport and an air force base.\", 'Only journalists from state media were allowed to visit it.']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-64-4c29ee593b96>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msentence\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msents\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;31m# sent = sentence.strip()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext_to_word_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'strip'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YH08EpoIFK3Q",
        "colab_type": "code",
        "outputId": "993c9f89-0b91-4aae-f7aa-bdd130d687dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 720
        }
      },
      "source": [
        "data[0, :, :]"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[178.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
              "       [178.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
              "       [178.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
              "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
              "       [178.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
              "       [178.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
              "       [178.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
              "       [178.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
              "       [178.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
              "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
              "       [178.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
              "       [178.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
              "       [178.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
              "       [178.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
              "       [178.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
              "       [178.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
              "       [178.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
              "       [178.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
              "       [178.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
              "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xb7V9k2KFC6h",
        "colab_type": "code",
        "outputId": "eedf5bc0-4c8b-4ead-8369-9acce65a58b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "data.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(49972, 20, 20)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "bFdmiDYcE144"
      },
      "source": [
        "### Check 3:\n",
        "\n",
        "Accessing first element in data should give something like given below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TsFWW5C2Djog",
        "outputId": "ec1daf8f-1e56-4e3d-b6e3-b40a06c406b3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1037
        }
      },
      "source": [
        "data[0, :, :]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[    3,   487,   474,  7113,    79,     3,  3687,   325,     5,\n",
              "         4200,   361,     4,  1525,  2913,     1,    89,    12,   451,\n",
              "            0,     0],\n",
              "       [  743,    96,  1044,     3,  2814,  1759,     7,   186,     3,\n",
              "         1219,  1070,  1987,   736,   154,     1,  2990,   458,     1,\n",
              "          543,   232],\n",
              "       [   89,  1052,  4057,  2314,    12,     3,  1073,  3248,    19,\n",
              "            1,    89,     2,  1751,     1,   518,  1980,    15,     9,\n",
              "            3,  2879],\n",
              "       [  182,  3691,   976,   196,  2515,    42,  6688,  1691,  1227,\n",
              "            5, 13011, 17379,     1,   762,    30,   722,  3931,    66,\n",
              "           87,     0],\n",
              "       [ 2314,    12,  1882,    38,  1076,   346,   793,     2,   356,\n",
              "          261,  1782,     5,  4396,    67,   486,     0,     0,     0,\n",
              "            0,     0],\n",
              "       [    1,   736,   186,    19,     1,   474,    32,     3,  7307,\n",
              "            4,  2122,  1227,     6,     3,  5195,     4,  1219,  1227,\n",
              "           12,  3308],\n",
              "       [   13,    12,    15,     8,   143,    25,   531,    63,     1,\n",
              "          474,  3679,    41,     9,  1825,     0,     0,     0,     0,\n",
              "            0,     0],\n",
              "       [ 3308,  5643,     4,     1,  5788,   620,    22,     1,   302,\n",
              "         3125,   786,     4,  1882,    12,     1,   474,    70,    23,\n",
              "          801,     2],\n",
              "       [   35,    17,     2,  1751,    15,    54,   119,    15,    70,\n",
              "           23,  4850,    41,  1885,    13,    12,     0,     0,     0,\n",
              "            0,     0],\n",
              "       [ 4664,  3279,    24,  3915,     2,     1,  1298,     4,  3028,\n",
              "         1630,    12,    15,     9,   187,  1423,     7,    56,    40,\n",
              "           96,     3],\n",
              "       [   35,    17,     2,  1076,    63,   497,    20,     3,   252,\n",
              "           41,   260,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0],\n",
              "       [  261,   743,    96,  1044,     3,  1765,  1759,   520,   273,\n",
              "           29,    12,    33,   702,   160,   818,  1423,     5,     1,\n",
              "         2068,     0],\n",
              "       [   34,     9,  2035,    10,   112,  5741,     6,    34,   562,\n",
              "          644,   104,    57,     4,     3,  2382,    34,   238,     3,\n",
              "          504,  1922],\n",
              "       [   35,   341,    15,     9,     3,  2053,   119,    35,   872,\n",
              "           24,  4397,  2541,  4258,  4851,    55,     1,   543,   232,\n",
              "            0,     0],\n",
              "       [    1,   254,     4,     1,   736,     8,   154,  4116,   346,\n",
              "          458,     6,    24,   152,   460,  1908,     0,     0,     0,\n",
              "            0,     0],\n",
              "       [  124,   896,    21,    48,   102,    37,  1803,     2,  1195,\n",
              "           15,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0],\n",
              "       [    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0],\n",
              "       [    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0],\n",
              "       [    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0],\n",
              "       [    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "hTG6JySHehkT"
      },
      "source": [
        "# Repeat the same process for the `Headings` as well. Use variables with names `texts_heading` and `articles_heading` accordingly. [5 marks] "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qDwjJxcGgBSJ",
        "colab_type": "text"
      },
      "source": [
        "texts = [] to store text of article as it is.\n",
        " \n",
        "articles = [] split the above text into a list of sentences."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kP1EJ1Quf8K_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "texts_heading=[]\n",
        "articles_heading=[]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ny4j-e8kAVYH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer2=keras.preprocessing.text.Tokenizer(num_words=MAX_NB_WORDS)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bOhZ36M8hwzh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "headlines=tokenizer2.fit_on_texts(df['Headline'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jMXuLtebj_PB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wordindex2=tokenizer2.word_index"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FqRo9Ko8_yEK",
        "colab_type": "code",
        "outputId": "cd0679d4-d341-4f31-ead7-e819d68f48ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(wordindex2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3879"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wQUiEs9bA6vl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "texts_heading = df['Headline']\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dPjsofXvBLly",
        "colab_type": "code",
        "outputId": "4abfe52d-01b0-44df-988d-b99045ea4d6e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "texts_heading.count"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method Series.count of 0        Soldier shot, Parliament locked down after gun...\n",
              "1        Tourist dubbed ‘Spider Man’ after spider burro...\n",
              "2        Luke Somers 'killed in failed rescue attempt i...\n",
              "3         BREAKING: Soldier shot at War Memorial in Ottawa\n",
              "4        Giant 8ft 9in catfish weighing 19 stone caught...\n",
              "                               ...                        \n",
              "49967    Pizza delivery man gets tipped more than $2,00...\n",
              "49968                   Pizza delivery man gets $2,000 tip\n",
              "49969     Luckiest Pizza Delivery Guy Ever Gets $2,000 Tip\n",
              "49970    Ann Arbor pizza delivery driver surprised with...\n",
              "49971    Ann Arbor pizza delivery driver surprised with...\n",
              "Name: Headline, Length: 49972, dtype: object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hjFeX6PfAsDG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "heading_sents = texts_heading.apply(sent_tokenize)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iq8c9cKjBZBQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "heading_data=np.zeros((49972,MAX_SENTS,MAX_SENT_LENGTH))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6xRVrfi6Buj4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i, sentence in enumerate(heading_sents):\n",
        "  #short_sents = re.split(sentence)\n",
        "  for j, sent in enumerate(str(sentence)):\n",
        "    if j < 20 and sent.strip():\n",
        "      words = text_to_word_sequence(str(sentence))\n",
        "      k = 0\n",
        "      for w in words:\n",
        "        if k < 20:\n",
        "          if w in wordindex2:#tokenizer.word_index:\n",
        "            heading_data[i, j, k] = wordindex2[w] #tokenizer.word_index[w]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GAMcLBoPB963",
        "colab_type": "code",
        "outputId": "a04bb5c1-9ad5-46a4-964b-ad12f1f05003",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 697
        }
      },
      "source": [
        "heading_data[0,:,:]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[176.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
              "       [176.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
              "       [176.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
              "       [176.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
              "       [176.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
              "       [176.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
              "       [176.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
              "       [176.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
              "       [176.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
              "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
              "       [176.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
              "       [176.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
              "       [176.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
              "       [176.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
              "       [176.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
              "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
              "       [176.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
              "       [176.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
              "       [176.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
              "       [176.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "iaH0Ey1qe_Co"
      },
      "source": [
        "### Now the features are ready, lets make the labels ready for the model to process.\n",
        "\n",
        "### Convert labels into one-hot vectors\n",
        "\n",
        "You can use [get_dummies](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.get_dummies.html) in pandas to create one-hot vectors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Zq-VcgM8fat1",
        "colab": {}
      },
      "source": [
        "labels=df['Stance']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lANTjyqoIFnN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labels=pd.get_dummies(labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8zeVSeUEILS_",
        "colab_type": "code",
        "outputId": "aaf2fde6-7b17-4bf0-d623-5af4fbbfc567",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "labels.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(49972, 4)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wmxp-lPdIQPG",
        "colab_type": "code",
        "outputId": "59fc7289-e7b1-41f9-c525-4f504dc9ed72",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "labels.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>agree</th>\n",
              "      <th>disagree</th>\n",
              "      <th>discuss</th>\n",
              "      <th>unrelated</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   agree  disagree  discuss  unrelated\n",
              "0      0         0        0          1\n",
              "1      0         0        0          1\n",
              "2      0         0        0          1\n",
              "3      0         0        0          1\n",
              "4      0         0        0          1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "40mA8FI2fcxZ"
      },
      "source": [
        "### Check 4:\n",
        "\n",
        "The shape of data and labels shoould match the given below numbers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vpEWEnjFfnFR",
        "outputId": "312006c9-6dff-4704-978e-d08131b483c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print('Shape of data tensor:', data.shape)\n",
        "print('Shape of label tensor:', labels.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of data tensor: (49972, 20, 20)\n",
            "Shape of label tensor: (49972, 4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "sDOxHdR3frDu"
      },
      "source": [
        "### Shuffle the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-Ra-yYTvfzRt",
        "colab": {}
      },
      "source": [
        "## get numbers upto no.of articles\n",
        "indices = np.arange(data.shape[0])\n",
        "## shuffle the numbers\n",
        "np.random.shuffle(indices)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LKnSqwIFf3Iy",
        "outputId": "3eb5ea22-4db3-44b6-c709-2da8084d86c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360
        }
      },
      "source": [
        "## shuffle the data\n",
        "data = data[indices]\n",
        "heading_data = heading_data[indices]\n",
        "## shuffle the labels according to data\n",
        "labels = labels[indices]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-65-7086770cf907>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mheading_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mheading_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m## shuffle the labels according to data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2999\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3000\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3001\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_to_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3002\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3003\u001b[0m         \u001b[0;31m# take() does not accept boolean indexers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_convert_to_indexer\u001b[0;34m(self, obj, axis, is_setter, raise_missing)\u001b[0m\n\u001b[1;32m   1283\u001b[0m                 \u001b[0;31m# When setting, missing keys are not allowed, even with .loc:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1284\u001b[0m                 \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"raise_missing\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mTrue\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mis_setter\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1285\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1286\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1287\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[0;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1090\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1091\u001b[0m         self._validate_read_indexer(\n\u001b[0;32m-> 1092\u001b[0;31m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis_number\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mraise_missing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1093\u001b[0m         )\n\u001b[1;32m   1094\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[0;34m(self, key, indexer, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1175\u001b[0m                 raise KeyError(\n\u001b[1;32m   1176\u001b[0m                     \"None of [{key}] are in the [{axis}]\".format(\n\u001b[0;32m-> 1177\u001b[0;31m                         \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1178\u001b[0m                     )\n\u001b[1;32m   1179\u001b[0m                 )\n",
            "\u001b[0;31mKeyError\u001b[0m: \"None of [Int64Index([40547,  7954, 34983,  6205, 21411, 11272, 44072,  7896, 34769,\\n            10521,\\n            ...\\n            15581, 40244, 18176, 45172, 43965, 23993, 12212,  6149, 18449,\\n            16427],\\n           dtype='int64', length=49972)] are in the [columns]\""
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "JcOFVfPBf9kA"
      },
      "source": [
        "### Split into train and validation sets. Split the train set 80:20 ratio to get the train and validation sets.\n",
        "\n",
        "\n",
        "Use the variable names as given below:\n",
        "\n",
        "x_train, x_val - for body of articles.\n",
        "\n",
        "x-heading_train, x_heading_val - for heading of articles.\n",
        "\n",
        "y_train - for training labels.\n",
        "\n",
        "y_val - for validation labels.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2neh9Wcof8iR",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "o5u3PTz3gEV-",
        "colab": {}
      },
      "source": [
        "x_train,x_val,y_train,y_val = train_test_split(data,labels,test_size = 0.2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MO7gOzloWT1a",
        "colab_type": "code",
        "outputId": "cfea4a05-d63e-48a5-d07e-682813e33420",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "print(x_train.shape)\n",
        "print(y_train.shape)\n",
        "\n",
        "print(x_val.shape)\n",
        "print(y_val.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(39977, 20, 20)\n",
            "(39977, 4)\n",
            "(9995, 20, 20)\n",
            "(9995, 4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "UTyvoHrsgMDw"
      },
      "source": [
        "### Check 5:\n",
        "\n",
        "The shape of x_train, x_val, y_train and y_val should match the below numbers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "KLEbiw2Yghe2",
        "outputId": "e2390c42-fcda-4165-ae0e-52bd515d8b1d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "print(x_train.shape)\n",
        "print(y_train.shape)\n",
        "\n",
        "print(x_val.shape)\n",
        "print(y_val.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(39978, 20, 20)\n",
            "(39978, 4)\n",
            "(9994, 20, 20)\n",
            "(9994, 4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "yNnoBtArhJ1E"
      },
      "source": [
        "### Create embedding matrix with the glove embeddings\n",
        "\n",
        "\n",
        "Run the below code to create embedding_matrix which has all the words and their glove embedding if present in glove word list."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4qDlKKt7f4yg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.chdir('/content/drive/My Drive/Colab Notebooks/Sequential NLP/')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "eKqn2IL2ZF8v",
        "outputId": "e60a5263-44dc-4258-cb73-0805a1ad7fbe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# load the whole embedding into memory\n",
        "embeddings_index = dict()\n",
        "f = open('glove.6B.100d.txt')\n",
        "for line in f:\n",
        "\tvalues = line.split()\n",
        "\tword = values[0]\n",
        "\tcoefs = np.asarray(values[1:], dtype='float32')\n",
        "\tembeddings_index[word] = coefs\n",
        "f.close()\n",
        "print('Loaded %s word vectors.' % len(embeddings_index))\n",
        "\n",
        "# create a weight matrix for words in training docs\n",
        "embedding_matrix = np.zeros((27427, 100))\n",
        "\n",
        "\n",
        "for word, i in wordindex.items():\n",
        "\tembedding_vector = embeddings_index.get(word)\n",
        "\tif embedding_vector is not None:\n",
        "\t\tembedding_matrix[i] = embedding_vector"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded 400000 word vectors.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "LRi4o3ZspDFU"
      },
      "source": [
        "# Try the sequential model approach and report the accuracy score. [10 marks]  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zSZDnPWkw2ZZ"
      },
      "source": [
        "### Import layers from Keras to build the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5AgwQsfMrzAQ",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "tf.keras.backend.clear_session()\n",
        "model = tf.keras.Sequential()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gpkVhIbx3gr1"
      },
      "source": [
        "### Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "G_8QXh-rmPFq",
        "outputId": "3c66dd0b-3cef-4474-cf5e-6e53934ac447",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "model.add(tf.keras.layers.Embedding(27427 + 1, #Vocablury size\n",
        "                                    50, #Embedding size\n",
        "                                    input_length=20) #Number of words in each review\n",
        "          )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jQ-aZf6Zh3Zp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.add(tf.keras.layers.LSTM(256, #RNN State - size of cell state and hidden state\n",
        "                               dropout=0.2, #Dropout before feeding the data to LSTM layer\n",
        "                               recurrent_dropout=0.2)) #Dropout applied to the output of LSTM layer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "C5Xrd-JQ3id7"
      },
      "source": [
        "### Compile and fit the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MlduHU2CovxC",
        "colab": {}
      },
      "source": [
        "model.add(tf.keras.layers.Dense(1,activation='sigmoid'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CM3yCmjQoCM3",
        "colab": {}
      },
      "source": [
        "from keras.losses import categorical_crossentropy\n",
        "from keras.optimizers import Adam\n",
        "optimizer = Adam(lr=0.001)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VAIVyxm3iEnu",
        "colab_type": "code",
        "outputId": "6bf356e2-66be-4dee-b038-e95c40527fa1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ain-lMcqiHZg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.fit(x_train,y_train,\n",
        "          epochs=20,\n",
        "          batch_size=32,          \n",
        "          validation_data=(x_val, y_val))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "R47A6Ysfev3l"
      },
      "source": [
        "## Build the same model with attention layers included for better performance (Optional)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8eS8n9nO6ILH",
        "colab_type": "text"
      },
      "source": [
        "# **Note , Due to Session of colab is getting crashed again and agian, I am uploading file as it is . Though code is correct, I couldn't show all the outputs. **"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZQ3TWuiAe1Uu",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wivJ-eVkfEOm",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "olqo5ytRe7eq"
      },
      "source": [
        "## Fit the model and report the accuracy score for the model with attention layer (Optional)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1zgxPrhzfBkv",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "z8507P94fDuX",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}